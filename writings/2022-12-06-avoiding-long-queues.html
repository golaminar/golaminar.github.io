<!DOCTYPE html>
<html>
<head>
    <title>Laminar | Avoiding Long Queues</title>
    <link rel="stylesheet" href="../site.css">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" type="image/x-icon" href="../favicon.ico">
    <meta property="og:title" content="Avoiding Long Queues">
    <meta property="og:type" content="article">
    <meta property="og:description" content="Why queues matter in software development: Part III of III">
    <meta property="og:image" content="https://www.golaminar.de/writings/thumbnails/2022-12-06-avoiding-long-queues.jpg">
    <meta property="og:url" content="https://www.golaminar.de/writings/2022-12-06-avoiding-long-queues.html">
    <meta name="twitter:card" content="summary_large_image">
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@3.9.1/dist/chart.min.js"></script>
    <link rel="stylesheet" href="illustrations.css">
    <link rel="stylesheet" href="queue-illustrations.css">
    <script src="illustration-helpers.js"></script>
</head>

<body class="writing">
    <header>
        <h1><a href="https://golaminar.de">Laminar</a></h1>
    </header>
    <main>
        <article>
            <h2>
                Avoiding Long Queues
                <br><span class="subtitle">Why queues matter in software development: Part III of III</span>
            </h2>
            <div class="byline"><span class="image-frame"><img src="../images/tom.jpg"></span><span
                    class="image-frame"><img src="../images/tiffany.jpg"></span>
                <nobr><span class="author"><a href="mailto:tom@golaminar.de">Tom</a> & <a
                            href="mailto:tiffany@golaminar.de">Tiffany</a></span><span class="date">6<sup>th</sup>
                        December 2022</span></nobr>
            </div>

            <p class="aside">This is part three of a series. Part 1, <a href="2022-11-29-two-weird-things.html">Two Weird Things</a>, aims to give you a better intuitive feel for how randomness makes queues likely to grow. Part 2, <a href="2022-12-06-the-cost-of-long-queues.html">The Cost of Long Queues</a>, outlines how uncontrolled queues lead to escalating costs.</p>

            <p>In the previous post, we saw that queues which we expected to remain under control in fact tended to get very long over time. Now that we understand cost of delay, we can see the danger to an organization attempting to deliver value by releasing software. As the queues grow, our delay costs escalate. Without intervention, a process that we intuitively expected to deliver value in a timely fashion, and continue to do so sustainably, actually leads us over time to a position where we cannot release enough value to cover our costs, or where our competitors beat us to the punch every time, and we can no longer function. That's obviously something we want to avoid. How on Earth can we do so?</p>

            <p>Three ways:</p>
            <ul>
                <li>Remove opportunities for queues to form if possible;</li>
                <li>Make hand-offs synchronous;</li>
                <li>Limit capacity utilization.</li>
            </ul>

            <p>First: if there is an opportunity to remove the ability for a queue to form, you should seriously consider taking it. For example: do you really need to manually test every change before it can be released to beta testers, or would it suffice to ... TODO: INSERT ACTUAL GOOD EXAMPLE OF A NEEDLESS STAGE GATE HERE.</p>

            <p>Second: if the hand-off is unavoidable, consider making it a synchronous, blocking action rather than asynchronous. TODO INSERT EXAMPLE THAT INVOLVES TWO PEOPLE - don't add stuff to the left because you're increasing demand on a queue you're already waiting in</p>

            <!-- <p>For example: if automated tests need to pass before a code change can be pushed to the main branch, it is better for the author of the code change to wait for the tests to run and pass (for example, by running them on their local machine) than for them to run them on a build server and work on the next change. Why is this? Well, the next change _also_ needs to pass the tests, and so allowing work on it while the tests for the previous change are running adds to the queue of changes needing to be tested. There are other benefits to making some portion of the automated test suite into a blocking set -- what I call a check-in build -- among them an incentive to keep the build running fast, and some guarantee that it's possible to run the software locally in some form. But for now let's concentrate on just the queue aspect. There are actually _two_ potential queues in this example. The other queue arises when the tests fail and the code change needs to be reworked. If the author is busy working on some other code change, they're not going to get to that rework as soon as it's clear it needs to be done, and so a rework queue can form.</p> -->

            <p>Other examples of unavoidable hand-offs that can benefit from being made synchronous include: security reviews: instead of working for six months, handing our stuff off to a security team for audit, and one month later we receiving a laundry list of vulnerabilities, we instead involve the security team as quickly as possible for any significant architectural change, and don't start work on it until we've agreed an approach; deployment to production; code review; and acceptance testing with the product owner.</p>

            <p>Third: if the hand-off is unavoidable and it's not feasible to make it a synchronous, blocking action, you should limit capacity utilization.</p>


            <p>"Capacity utilization? What's that? Just when you were starting to get practical and make some concrete recommendations, you throw in another theory term?"</p>

            <p>Yes, sorry about that. We need to take another quick dive into queueing theory to understand what I'm talking about here, and then I promise it will get practical again.</p>

            <p>In queueing theory -- and maybe you saw this when playing with the airline check-in interactive in Part 1 -- there is a relation between the expected size of a queue and the extent to which the server's capacity is used. If a server is idle most of the time -- they can serve customers in 10 seconds on average, and customers arrive once every minute on average, or a capacity utilization of 1/6 or 16.67% -- then the queue will stay under control and stay very short. At the other extreme, perhaps obviously, if customers arrive every 5 seconds on average and the server still takes 10 seconds per customer (a capacity utilization of 200%), the queue will continue to grow over time with no upper bound. The exact shape of the relationship between capacity utilization is an exponential relation, as the graph below shows.</p>

            <figure>GRAPH GOES HERE</figure>

            <p>What we can see here is that when capacity utilization is at or below roughly 80% (the server takes 8 seconds per customer, and customers arrive every 10 seconds) the queue size is fairly stable. Once we pass that point, we start to be on the steep part of the exponential curve, and the queue size quickly gets to unsustainably high levels, with correspondingly high cost of delay. This accounts for those surprising numbers from part 1, where a server with an average service time of 120 seconds, serving arrivals with an average interval of 121 seconds (capacity utilization: 120/121 = 99.17%) had an expected average queue size of 118, whereas two servers working the same queue at the same rate (capacity utilization: 60/121 = 49.59%) had an expected average queue size of 0.3.</p>

            <p>Since capacity utilization has an exponential relationship with queue size, anything on the right of that roughly 80% mark looks pretty scary and anything on the left looks pretty reasonable. Comparing the queue sizes at 65% and 80% capacity utilization, there isn't a huge difference. Comparing between 75 and 90%, there is. So it seems a good rule of thumb to shoot for capacity utilization for our processes of roughly 80%, but not to worry too much about being exact.</p>

            <p>How do we achieve that? Well, at first glance it's not easy. Let's take a look at the macro level: a Scrum team could decide they want to control capacity utilization by only taking on 80% of the story points their velocity suggests they can handle in an average sprint. And indeed, if they could do this accurately and not take on any unplanned work during the duration of their sprint, they would be controlling capacity utilization at 80%. But this would require their estimation of story points to be _really_ accurate. Being off by 20% on an estimate isn't uncommon, but would totally blow up this team's strategy for controlling their capacity utilization.</p>

            <p>When we look at the micro level, it's much more difficult to understand how we would apply this kind of direct approach to controlling capacity utilization. Take code review as an example. The available capacity for this activity is elastic, since it's done by people who also do other things. There's a theoretical maximum capacity -- all the developers exclusively do code review and no other activity -- and a theoretical minimum -- no developer ever performs code review -- and obviously, the former case would lead to there being nothing in the code review queue and the latter would lead to a review queue that grows forever. So the appropriate amount of time to spend on code review as a team lies somewhere in between the two extremes. But I'm at a loss for how one would determine this amount of time in advance so that you would hit 80% capacity utilization for the process.</p>

            <p>With multiple queues throughout our processes and the inherent unpredictability of software development (you might say the inherent unpredictability of life) the direct approach seems doomed to failure at first contact with reality. Fortunately, there is a way to control capacity utilization <em>indirectly</em>.</p>

            <p>Below is a simulation of a single process where we apply a work-in-progress (WIP) limit to the queue. You can change the WIP limit to be applied, and let the process run its course. What you'll see is that over time, a WIP limit creates situations where there is excess capacity available, but there is nothing in the queue waiting to be served. So instead of the server being occupied 100% of the time (100% capacity utilization) they are sometimes waiting for short periods of time (less than 100% capacity utilization).</p>

            <figure id="figure-backlog-growth" class="illustration">

                <div class="controls">
                    <button class="start-iteration">Start Interation</button>
                    <button class="end-iteration">End Interation</button>
                </div>

                <div class="cols">

                    <div class="col">
                        <table class="board no-wip">
                            <thead>
                                <tr>
                                    <th colspan="2">
                                        Backlog has no WIP limit
                                    </th>
                                </tr>
                                <tr>
                                    <td colspan="2">
                                        All items wait in the backlog until they are eventually completed.
                                    </td>
                                </tr>
                                <tr>
                                    <th>
                                        Backlog
                                    </th>
                                    <th>
                                        Done
                                    </th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td class="backlog-column"></td>
                                    <td class="done-column">
                                        <table class="iterations">
                                            <tbody>
                                                <tr>
                                                    <td>
                                                    </td>
                                                    <td>
                                                    </td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                    </td>
                                                    <td>
                                                    </td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                    </td>
                                                    <td>
                                                    </td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                    </td>
                                                    <td>
                                                    </td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                    </td>
                                                    <td>
                                                    </td>
                                                </tr>
                                            </tbody>
                                        </table>
                                    </td>
                                </tr>
                            </tbody>
                            <tfoot>
                                <tr>
                                    <td colspan="2">
                                        The backlog grows uncontrolled. The team is always working at capacity.
                                    </td>
                                </tr>
                            </tfoot>
                        </table>
                    </div>

                    <div class="col">
                        <table class="board with-wip">
                            <thead>
                                <tr>
                                    <th colspan="2">
                                        Backlog is limited to 6 items
                                    </th>
                                </tr>
                                <tr>
                                    <td colspan="2">
                                        When the backlog grows to above its limit, excess items are immediately rejected.
                                    </td>
                                </tr>
                                <tr>
                                    <th>
                                        Backlog
                                    </th>
                                    <th>
                                        Done
                                    </th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td class="backlog-column"></td>
                                    <td class="done-column">
                                        <table class="iterations">
                                            <tbody>
                                                <tr>
                                                    <td>
                                                    </td>
                                                    <td>
                                                    </td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                    </td>
                                                    <td>
                                                    </td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                    </td>
                                                    <td>
                                                    </td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                    </td>
                                                    <td>
                                                    </td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                    </td>
                                                    <td>
                                                    </td>
                                                </tr>
                                            </tbody>
                                        </table>
                                    </td>
                                </tr>
                            </tbody>
                            <tfoot>
                                <tr>
                                    <td colspan="2">
                                        The backlog is never allowed to grow. Occasionally, the team has excess capacity.
                                    </td>
                                </tr>
                            </tfoot>
                        </table>
                    </div>
                </div>

                <figcaption>This illustration shows an example of how a backlog grows over time when it is unbounded and the number of items that appear is random follow a <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson process</a>. When a backlog is left to grow unbounded, the team will always be working at full capacity, and never has the opportunity to catch up on old items. Under these conditions, the backlog grow, causing new items to be left waiting longer and longer.</figcaption>
            </figure>

            <p>How does this happen? Again, it's all about randomness. The server deals with 5 items per hour on average, but not the same amount every hour. TODO KEEP THE EXAMPLE TO THE TEAM That means that in some hours, she is able to deal with 7 items. Other hours, she can only deal with 3. With no WIP limit on the queue and an arrival rate close to the service rate, there will almost always be something for her to work on and her capacity utilization will be at or near 100%, so the queue will grow. With a WIP limit on the queue -- let's say it's 6, as we set it by default -- there will be times when more items come in and we reject demand, capping the queue size at 6. It's possible that those times coincide with the times when the server is able to serve quicker than average, leading to her running out of work before new items come into the queue and having to wait (less than 100% capacity utilization.)</p>

            <p>That's a very reasonable question. First, it's important to remember that while we're illustrating the workings of WIP limits with a single queue, in reality we are dealing with multiple adjacent queues, and they are being worked on by multi-talented people. So when, for example, the 'being programmed' column is at its WIP limit, and no new code can be written, this does not mean that our developers have nothing they can do and are forced to sit idle, rejecting any new work that comes their way. Instead, they can look at the adjacent columns (ideally the columns to the right)</p>

            <p>"OK," you might say, "but how does this look in practice? It sounds a bit scary when we say that we 'reject demand'. The whole point of this is supposed to be that we improve our process so that we can meet our users' and stakeholders' demands, isn't it?"</p>

            <p>That's a very reasonable question. First, it's important to remember that while we're illustrating the workings of WIP limits with a single queue, in reality we are dealing with multiple adjacent queues, and they are being worked on by multi-talented people. So when, for example, the 'being programmed' column is at its WIP limit, and no new code can be written, this does not mean that our developers have nothing they can do and are forced to sit idle, rejecting any new work that comes their way. Instead, they can look at the adjacent columns (ideally the columns to the right)</p>

            <p>What does the world look like when WIP limits are applied? We're focusing and finishing things, not starting.</p>

<!-- * Why haven't I talked about controlling and reducing randomness? Six Sigma is a thing, right? We don't want things to be unpredictable.
	* Software is inherently unpredictable
	* The value of what we do is often in direct proportion to how novel -- and hence how unpredictable it is.
	* Even if we could, and even if we wanted to, reduce randomness, it wouldn't help us at high capacity utilization levels. GRAPH HERE
* OK, but how bad are queues really? I don't want people sitting idle.
	* Of course it's an optimization. Airline check-in economics are a bit different from software development economics. We're trading off cost of capacity vs cost of delay.
		* GRAPH HERE, PROBABLY SOME ABILITY TO TWEAK VARIABLES
	* The thing is: if you pay 0 cost of capacity, you eventually pay _infinite_ cost of delay. You can build new stuff for a while, but you'll get slower and slower, and eventually you have no ability to innovate and bring new stuff to the market in a timely fashion, so your competitors  eat your lunch. If you want to avoid this, you must introduce _some_ slack into the system. Things need to be idle at least some of the time so that there's an ability to deal with new information. You could crunch all the numbers and optimize to the nth degree, or you could just bear in mind that 80% is roughly toward the bottom end and shoot for that (or even better, apply WIP limits and let the randomness do it for you.)
* So in summary, what do I suggest you do?
	* Recognize the massive impact of cost of delay. Build it into your financial reporting if you can.
	* Whenever you see an opportunity for a queue to form, ask yourself: is it possible to avoid this queue? If I can't avoid the queue, can I make the asynchronous hand-off into a synchronous and blocking operation?
	* Where queues exist, reduce capacity utilization. Don't try to do it directly -- apply WIP limits. EXAMPLES OF WIP LIMITS HERE --> -->

            <script src="backlog-growth-illustrations.js"></script>

            <p class="author-bio">
                Tom Stuart and Tiffany Conroy are consultants with a combined 35+ years of experience developing
                software and leading teams.
                They help software teams change their processes to eliminate or reduce queues in their development
                cycle.
                Hire them!
                Get in touch at <a href="mailto:hello@golaminar.de">hello@golaminar.de</a>.
            </p>
            <p class="footnote" id="footnote-1"><a href="#footnote-1-source">1</a>: PLACEHOLDER FOOTNOTE.</p>
        </article>
    </main>
    <footer>
        <div class="footer-container">
            <span class="names"><a href="https://www.linkedin.com/in/tconroy/">Tiffany Conroy</a> & <a
                    href="https://www.linkedin.com/in/another-tom-stuart/">Thomas Stuart</a> GbR</span>
            <span class="email"><a href="mailto:hello@golaminar.de">hello@golaminar.de</a></span>
            <span class="address">Colbestr. 29, 10247 Berlin</span>
        </div>
    </footer>
</body>

</html>
