---
published: false
layout: writing
title: Avoiding Long Queues
subtitle: "Why queues matter in software development: Part I of a series"
description: We obviously want to avoid uncontrolled costs and allowing our competitors beat us to the punch. How on Earth can we do so?
image: 2022-12-13-avoiding-long-queues.png
custom_css:
- illustrations
- queue-illustrations
custom_js:
- illustration-helpers
---
            <div class="byline"><span class="image-frame"><img src="../images/tom.jpg"></span><span
                    class="image-frame"><img src="../images/tiffany.jpg"></span>
                <nobr><span class="author"><a href="mailto:tom@golaminar.de">Tom</a> & <a
                            href="mailto:tiffany@golaminar.de">Tiffany</a></span><span class="date">13<sup>th</sup>
                        December 2022</span></nobr>
            </div>

            <p class="aside">This is part three of a series. Part 1, <a href="2022-11-29-two-weird-things.html">Two Weird Things</a>, aims to give you a better intuitive feel for how randomness makes queues likely to grow. Part 2, <a href="2022-12-06-the-cost-of-long-queues.html">The Cost of Long Queues</a>, outlines how uncontrolled queues lead to escalating costs.</p>

            <p>In previous posts, we saw that queues which we expected to remain under control in fact tended to get very long over time. Now that we understand cost of delay, we can see the danger to an organization that delivers value by releasing software. As the queues grow, our delay costs escalate.</p>

            <p>Without intervention, a process that we intuitively expected to deliver value in a timely fashion, and continue to do so sustainably, actually leads us over time to a position where we cannot release enough value to cover our costs, or where our competitors beat us to the punch every time.</p>

            <p>How can we avoid such a situation? Three ways:</p>
            <ul>
                <li>Remove opportunities for queues to form, if possible;</li>
                <li>Make hand-offs synchronous;</li>
                <li>Limit capacity utilization.</li>
            </ul>

            <h2>Remove opportunities for queues to form</h2>

            <p>Queues can form throughout your development process wherever there is a hand-off from one person to another, or from one type of work phase to another. If there is an opportunity to remove such a hand-off, you should seriously consider taking it. For example: do you really need to manually test every change before it can be released to beta testers, or would it suffice to manually test in the beta version?</p>

            <p>Take an inventory of all the points in your process where a change waits before someone carries it to the next stage, and evaluate what benefits that activity brings, and whether there is an way to achieve the same benefit without preventing a change from being integrated and deployed.</p>

            <h2>Make hand-offs synchronous</h2>

            <p>If a hand-off is unavoidable, consider making it a synchronous, blocking action rather than asynchronous. For example, if your compliance regulations require that a second person signs off on a code change, make it someone‚Äôs priority to perform such sign-offs ahead of any other work, so that they are aways available to do so, and make sure that the author of the code change doesn't start on another task (adding to the queue) while waiting for the signoff.</p>

            <p>Other examples of unavoidable hand-offs that can benefit from being made synchronous include: security reviews; deployment to production; code review; and acceptance testing with the product owner.</p>

            <h2>Limit capacity utilization</h2>

            <p>If the hand-off is unavoidable and it‚Äôs not feasible to make it a synchronous, blocking action, you should limit
            capacity utilization.</p>

            <p>‚ÄúCapacity utilization? What‚Äôs that? Just when you were starting to get practical and make some concrete recommendations, you throw in another theory term?‚Äù</p>

            <p>Yes, sorry about that. We need to take another quick dive into queueing theory to understand what I‚Äôm talking about here, and then I promise it will get practical again.</p>

            <p>In queueing theory ‚Äî and maybe you saw this when playing with the <a href="2022-11-29-two-weird-things.html#figure-MM1-queue">airline check-in interactive illustration in Part 1</a> ‚Äî there is a relation between the expected size of a queue and the extent to which the server‚Äôs capacity is used. If a server can serve a customer in 10 seconds on average, and customers arrive once every minute on average, the capacity utilization is 1/6 or 16.7%. The server will be idle most of the time, and the queue will stay under control and stay very short. At the other extreme, perhaps obviously, if customers arrive every 5 seconds on average and the server still takes 10 seconds per customer (a capacity utilization of 200%), the queue will grow over time with no upper bound. The exact shape of the relationship between capacity utilization is an exponential relation, as the graph below shows.</p>

            <figure id="figure-capacity-utilization" class="illustration">
                <canvas id="capacity-utilization-graph-canvas"></canvas>
                <figcaption>The graph shows the steady-state expected length of a queue against its capacity utilization. As capacity utilization approaches 100%, the length of the queue extends to infinity. The expected length of an M/M/1 queue is given by <var>p<sup>2</sup>/1-p</var>, where <var>p</var> is capacity utilization.</figcaption>
            </figure>
            <script src="capacity-utilization-illustration.js"></script>

            <p>What we can see in the graph is that when capacity utilization is at or below roughly 80% (i.e. the server takes 8 seconds per customer, and customers arrive every 10 seconds) the queue size is fairly stable. Once we pass that point, we start to be on the steep part of the exponential curve, and the queue size quickly gets to unsustainably high levels, with correspondingly high cost of delay. This accounts for those surprising numbers from part 1, where a server with an average service time of 120 seconds, serving arrivals with an average interval of 121 seconds (capacity utilization: 120/121 = 99.17%) had an expected average queue size of 118, whereas two servers working the same queue at the same rate (capacity utilization: 60/121 = 49.59%) had an expected average queue size of 0.3.</p>

            <p>Since capacity utilization has an exponential relationship with queue size, anything on the right of that roughly 80% mark looks pretty scary and anything on the left looks pretty reasonable. Comparing the queue sizes at 65% and 80% capacity utilization, there isn‚Äôt a huge difference. Comparing between 75% and 90%, there is. So it seems a good rule of thumb to shoot for capacity utilization for our processes of roughly 80%, but not to worry too much about being exact.</p>

            <h2>How to limit capacity utilization?</h2>

            <p>So we agree on the value of limiting capacity utilization, and we have a target of 80%. How do we achieve that? Well, at first glance it‚Äôs not easy.</p>

            <!-- is this paragraph adding to the argument? -->
            <p>Let‚Äôs take a look at the macro level: a Scrum team could decide they want to control capacity utilization by only taking on 80% of the story points their velocity suggests they can handle in an average sprint. And indeed, if they could do this accurately and not take on any unplanned work during the duration of their sprint, they would be controlling capacity utilization at 80%. But this would require their estimation of story points to be <em>really</em> accurate. Being off by 20% on an estimate isn‚Äôt uncommon, but would totally blow up this team‚Äôs strategy for controlling their capacity utilization.<sup><a href="#footnote-1" id="footnote-1-source">1</a></p>

            <p>When we look at the micro level of individual queues within a software development process, it‚Äôs much more difficult to understand how we would apply this kind of direct approach to controlling capacity utilization. Take code review as an example. The available capacity for this activity is elastic, since it‚Äôs done by people who also do other things. There‚Äôs a theoretical maximum capacity ‚Äî all the developers exclusively do code review and no other activity ‚Äî and a theoretical minimum ‚Äî no developer ever performs code review ‚Äî and obviously, the former case would lead to there being nothing in the code review queue and the latter would lead to a review queue that grows forever. So the appropriate amount of time to spend on code review as a team lies somewhere in between the two extremes. But I‚Äôm at a loss for how one would determine this amount of time in advance so that you would hit 80% capacity utilization for the process.</p>

            <p>With multiple queues throughout our processes and the inherent unpredictability of software development (you might say the inherent unpredictability of life) the direct approach seems doomed to failure at first contact with reality. Fortunately, there is a way to control capacity utilization <em>indirectly</em>.</p>

            <p>Below is a simulation of a single process where we apply a work-in-progress (WIP) limit to the queue. You can change the WIP limit to be applied, and let the process run its course. What you‚Äôll see is that over time, a WIP limit creates situations where there is excess capacity available, but there is nothing in the queue waiting to be served. So instead of the team being occupied 100% of the time (100% capacity utilization) they are sometimes waiting for short periods of time (less than 100% capacity utilization).</p>

            <figure id="figure-backlog-growth" class="illustration">

                <div class="controls">
                    <div>
                        <button title="Load new data" data-action="reload">üîÑ</button>
                        <button title="Jump backward" data-direction="backward" data-size="jump">‚è™</button>
                        <button title="Step backward" data-direction="backward" data-size="step">‚óÄÔ∏è</button>
                    </div>

                    <span class="frame-title">Start of Iteration 1</span>

                    <div>
                        <button title="Step forward" data-direction="forward" data-size="step">‚ñ∂Ô∏è</button>
                        <button title="Jump forward" data-direction="forward" data-size="jump">‚è©</button>
                        <button title="Jump to the end" data-direction="forward" data-size="zoom">‚è≠</button>
                    </div>
                </div>

                <div class="cols">
                    <div class="board-example no-wip">
                        <span class="title">Backlog has <nobr>no WIP limit</nobr></span>
                        <span class="explanation limit-explanation">All items wait in the backlog until they are eventually completed.</span>

                        <div class="board cols">
                            <div class="column backlog-column">
                                <span class="title">Backlog</span>
                                <div class="items holder"></div>
                                <span class="explanation frame-explanation"></span>
                            </div>
                            <div class="column done-column">
                                <span class="title">Done</span>
                                <div class="iterations holder"></div>
                                <span class="explanation frame-explanation"></span>
                            </div>
                        </div>
                        <span class="explanation capacity-explanation"></span>
                        <span class="explanation behaviour-explanation">The team is nearly always working at capacity, but the backlog grows uncontrolled.</span>
                    </div>

                    <div class="board-example with-wip">
                        <span class="title">Backlog is <nobr>limited to 6 items</nobr></span>
                        <span class="explanation limit-explanation">Excess items are rejected when the backlog is above its limit.</span>

                        <div class="board cols">
                            <div class="column backlog-column">
                                <span class="title">Backlog</span>
                                <div class="items holder"></div>
                                <span class="explanation frame-explanation"></span>
                            </div>
                            <div class="column done-column">
                                <span class="title">Done</span>
                                <div class="iterations holder"></div>
                                <span class="explanation frame-explanation"></span>
                            </div>
                        </div>
                        <span class="explanation capacity-explanation"></span>
                        <span class="explanation behaviour-explanation">The backlog is never allowed to grow. Occasionally, the team has excess capacity.</span>
                    </div>
                </div>

                <figcaption>This illustration shows an example of how a backlog grows over time when it is unbounded and the number of items that appear is random follow a <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson process</a>, compared to one that is limited in length. When a backlog is left to grow unbounded, the team will always be working at full capacity, and might never have the opportunity to catch up. Under these conditions, the backlog grows, causing the newest items to be left waiting longer and longer, accumulating high cost of delay.</figcaption>
            </figure>
            <script src="backlog-growth-illustrations.js"></script>

            <p>How does this happen? Again, it‚Äôs all about randomness. The team deals with 5 items per cycle on average, but not the same amount every cycle. That means that in some cycles, they are able to deal with 7 items. Other cycles, they can only deal with 3. With no WIP limit on the queue and an arrival rate close to the service rate, there will almost always be something left over at the end of a cycle for them to work on and their capacity utilization will be at or near 100%, so the queue will grow. With a WIP limit on the queue ‚Äî let‚Äôs say it‚Äôs 6, as we set it by default ‚Äî there will be times when more items come in and we reject demand, capping the queue size at 6. It‚Äôs possible that those times coincide with the times when the team is able to work quicker than average, leading to them running out of work before new items come into the queue and therefore having to wait (less than 100% capacity utilization.)</p>

            <p>What about controlling and reducing randomness? Six Sigma is a thing, right? Unfortunately, we aren‚Äôt manufacturing bolts or performing repetitive service tasks. Software developement and operation is inherently unpredictable. The value of what we do is often in direct proportion to how novel ‚Äî and hence how unpredictable ‚Äî it is. Even if we could reduce randomness, that wouldn‚Äôt help us at high capacity utilization levels; lowering the variablity will shift the inflection point of our curve, but so long as there is any variablity, the queue length will always be unbounded as capacity utilization approaches 100%.</p>

            <h2>Rejecting work and idle hands?</h2>

            <p>‚ÄúOK,‚Äù you might say, ‚Äúbut how does this look in practice? It sounds a bit scary when we say that we ‚Äòreject demand‚Äô and that the team has to wait. The whole point of this is supposed to be that we improve our process so that we can meet our users‚Äô and stakeholders‚Äô demands and that we work effectively, isn‚Äôt it?‚Äù</p>

            <p>That‚Äôs a very reasonable question. First, it‚Äôs important to remember that while we‚Äôre illustrating the workings of WIP limits with a single queue, in reality we are dealing with multiple adjacent queues, and they are being worked on by multi-talented people. So when, for example, the ‚Äòactively being programmed‚Äô column is at its WIP limit, and no new code can be written, this does not mean that our developers have nothing they can do and are forced to sit idle, rejecting any new work that comes their way. Instead, they can look at the adjacent columns (ideally the columns to the right) and find work needing to be completed there. It helps the team shift their focus away from being <em>busy</em> and starting lots of things to being <em>productive</em> and making sure items get finished.</p>

            <p>Second, although it can happen that the team (or an individual) runs out of work and is made to wait because of WIP limits, this is not a situation that you can expect to occur for prolonged periods of time. 80% capacity utilization doesn‚Äôt manifest as people working for four days per week and then sitting idle on a Friday, waiting for new work to be offered. Instead, you would expect to see people waiting ten minutes at a time while the process they depend on clears its queue and they can move on, and multiple short waits like this add up to 20% of their time.</p>

            <!-- Not sure if we want to keep this. If we do, it needs to be expanded to be more narrative. -->
            <p>What does the world look like when WIP limits are applied? We‚Äôre focussed on finishing things, not starting them.</p>

            <h2>Avoid the queues you can, control the queues you can‚Äôt</h2>

            <p>So in summary, what do I suggest you do to avoid long queues, and hence avoid high costs of delay while staying nimble and responsive to your market demands?</p>

            <ul>
                <li>Recognize the massive impact of cost of delay. Build it into your financial reporting if you can.</li>
                <li>Whenever you see an opportunity for a queue to form, ask: is it possible to avoid this queue? If we can‚Äôt
                avoid the queue, can we make the asynchronous hand-off into a synchronous and blocking operation?</li>
                <li>Where queues exist, introduce slack into the system by reducing capacity utilization. Don‚Äôt try to do it directly ‚Äî consider using WIP limits instead.</li>
            </ul>

            <h2>Establishing good WIP limits</h2>

            <p>So, you are convinced. Now you need to establish WIP limits for you team. How do you go about that?</p>

            <p>Much has been written on this topic, and we had hoped to be able to link to a ‚Äòready-made‚Äô article outlining a recommended to setting and monitoring work-in-progress limits. Unfortunately, we found that we could not link to any of the articles we found without some additional commentary and/or caveats.</p>

            <p>So instead, we would like to invite you participate in a <strong>live reading and discussion session</strong> where we can digest the articles we found as a group, share our learnings, and discuss how the articles‚Äô guidance matches up with the goals of establishing WIP limits, and how the suggested approach would land with your teams. The session will take place on the 2nd of February, and we‚Äôd love to see you there. We will share the list of articles ahead of time, as well as discussion prompts, to ensure a lively and thoughtful conversation. <a href="https://forms.gle/RJ1LHy31D5v65ztz9">Sign up now to attend!</a></p>

            <p>If you are looking for support on these topics in your workplace ‚Äî from promoting and investigations, to hands-on training and change management ‚Äî we‚Äôre available. <a href="https://calendly.com/golaminar/30-minute-call">Book a time to chat with us!</a></p>

            <hr>

            <h2>Further reading</h2>

            <p>There are many more aspects to this topic than we‚Äôve covered so far. We may add more parts to this series in the future. However, there are already many resources you can turn to now for further study. Here are some that we recommend:</p>

            <ul>
                <li><a href="https://books.google.de/books/about/The_Principles_of_Product_Development_Fl.html?id=1HlPPgAACAAJ&redir_esc=y"><i>The Principles of Product Development Flow</i></a> by Donald G. Reinertsen ‚Äî every ‚Äúbut wait, what about ‚Ä¶‚Äù question you have about queues in product developement workflow are answered in this book. A classic.</li>
                <li><a href="https://www.google.de/books/edition/The_Goal/6vdJLwEACAAJ?hl=de"><i>The Goal</i></a> by Eliyahu Goldratt ‚Äî If you‚Äôre looking to dig even deeper on principles, as opposed to specific practices, <i>The Goal</i> has you covered. Look past its slightly cheesy ‚Äòbusiness novel‚Äô format and you‚Äôll find an excellent and insightful examination of where we should really focus our efforts if we want our organizations to be successful.</li>
            </ul>


            <!-- I imagine we could do this in smaller print somewhere that doesn't make it look like a footnote? -->
            <h2>Acknowledgements</h2>
            <p>We were very grateful for feedback, comments, and other input provided by our friends and colleagues: Esther Weidauer, Justine Lera, Denis Defreyne, Fronx Wurmus, James Coglan, Alicia Hickey, Benjamin Schumann, and Michele Guido.</p>

            <p class="author-bio">
                Tom Stuart and Tiffany Conroy are consultants with a combined 35+ years of experience developing
                software and leading teams. They help software teams change their processes to eliminate or reduce queues in their development cycle. Hire them!
                Get in touch at <a href="mailto:hello@golaminar.de">hello@golaminar.de</a>.
            </p>

            <p class="footnote" id="footnote-1"><a href="#footnote-1-source">1</a>: Some of you might be looking at the recommended 80% capacity utilization and be thinking of schemes like 20% time, in which team members are allowed to use their Fridays to work on self-directed projects outside of the main backlog, and wondering if this is a good way to control capacity utilization. I don't recommend this. We want to control capacity utilization so that, in the times when there is unexpected extra demand on the team, the team has a higher chance of being available to work on that demand. If we make extra headroom available by giving them 20% time, we can only get this benefit by expecting them to sacrifice the 20% time when it's a busy time.</p>
            <!-- this footnote seems to be orphaned -->
            <!-- <p class="footnote" id="footnote-1"><a href="#footnote-1-source">1</a>: serving customers in 10 seconds who arrive every 60 seconds will result in an capacity utilization of 1/6 or 16.67%.</p> -->
